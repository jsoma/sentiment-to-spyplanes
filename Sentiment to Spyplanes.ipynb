{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment to Spyplanes\n",
    "\n",
    "You can see the content this notebook was based on (with a lot more words) [right over here](https://investigate.ai/investigating-sentiment-analysis/comparing-sentiment-analysis-tools/).\n",
    "\n",
    "Our sentences:\n",
    "\n",
    "* I love this kitten\n",
    "* That article was pure garbage\n",
    "* Your feedback is appreciated :)\n",
    "* Your feedback is appreciated ðŸ¤®\n",
    "* That restaurant was great, but I'm not sure if I'll go there again!\n",
    "\n",
    "Before we get started on sentiment, though, we need to **do a little setup.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install what needs installing\n",
    "\n",
    "We'll need to install a few tools before we move on.\n",
    "\n",
    "* **matplotlib:** graphing library\n",
    "* **pandas:** data analysis (although we're only using it to build a table)\n",
    "* **NLTK:** text and sentiment analysis tool (old workhorse)\n",
    "* **TextBlob:** text and sentiment analysis tool (a bit more convenient than NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib pandas nltk textblob eli5 twython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now a little additional setup for our old friend NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a couple datasets for later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet -O reviews-marked.csv https://github.com/jsoma/sentiment-to-spyplanes/blob/master/reviews-marked.csv?raw=true\n",
    "!wget --quiet -O sentiment140-subset.csv https://github.com/jsoma/sentiment-to-spyplanes/blob/master/sentiment140-subset.csv?raw=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring our sentences\n",
    "\n",
    "Let's feed our sentences in **NLTK** and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "\n",
    "sia.polarity_scores(\"I love this kitten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I hate this keyboard\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Your feedback is appreciated :)\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Your feedback is appreciated ðŸ¤®\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"That restaurant was great, but I'm not sure if I'll go there again\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This article was pure garbage\"\n",
    "sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob\n",
    "\n",
    "TextBlob is another library for performing text analysis, and it has **two ways** of performing sentiment analysis.\n",
    "\n",
    "### Option A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I love this kitten\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I hate this keyboard\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"This article was pure garbage\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobber = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "blob = blobber(\"This article was pure garbage\")\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing all of our sentiment analysis tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "sentences = pd.DataFrame({'content': [\n",
    "    \"I love this kitten\",\n",
    "    \"I hate keyboard\",\n",
    "    \"I appreciate the feedback :)\",\n",
    "    \"I appreciate the feedback ðŸ¤®\",\n",
    "    \"This article was garbage\",\n",
    "    \"This article was pure garbage\",\n",
    "    \"That restaurant was great, but I'm not sure if I'll go there again\",\n",
    "    \"I'm not sure how I feel about toast\",\n",
    "    \"Did you see the baseball game yesterday?\",\n",
    "    \"The package was delivered late and the contents were broken\",\n",
    "    \"Trashy television shows are some of my favorites\",\n",
    "    \"I'm seeing a Kubrick film tomorrow, I hear not so great things about it.\",\n",
    "    \"I find chirping birds irritating, but I know I'm not the only one\",\n",
    "    \"Sick moves, bro\",\n",
    "    \"ur a nazi\",\n",
    "]})\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(content):\n",
    "    blob = TextBlob(content)\n",
    "    nb_blob = blobber(content)\n",
    "    sia_scores = sia.polarity_scores(content)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'content': content,\n",
    "        'textblob': blob.sentiment.polarity,\n",
    "        'textblob_bayes': nb_blob.sentiment.p_pos - nb_blob.sentiment.p_neg,\n",
    "        'nltk': sia_scores['compound'],\n",
    "    })\n",
    "\n",
    "scores = sentences.content.apply(get_scores)\n",
    "scores.style.background_gradient(cmap='RdYlGn', axis=None, low=0.4, high=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's it used for?\n",
    "\n",
    "* UpShot's Trump + State of the Union: https://www.nytimes.com/interactive/2017/02/28/upshot/trump-sounds-different-tone-in-first-address-to-congress.html\n",
    "* WaPo's App Stores: https://www.washingtonpost.com/technology/2019/11/22/apple-says-its-app-store-is-safe-trusted-place-we-found-reports-unwanted-sexual-behavior-six-apps-some-targeting-minors/\n",
    "* AJC's Doctors and Sex Abuse: http://doctors.ajc.com/\n",
    "* BuzzFeed's Spies in the Skies: https://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes\n",
    "* Trump on Twitter: https://www.nytimes.com/interactive/2019/11/02/us/politics/trump-twitter-presidency.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our sentiment analysis tools\n",
    "\n",
    "We'll start by reading in a list of tweets that are tagged as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sentiment140-subset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectors = vectorizer.fit_transform(df.text)\n",
    "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our classifiers\n",
    "\n",
    "Now that we have a list of words, we can say hey, learn to associate the appearance of these words with either positivity or negativity!\n",
    "\n",
    "And did I mention that not only do we get to pick our dataset, there are also **multiple kinds of classifiers?** Let's try two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Word counts + positive/negative\n",
    "X = words_df\n",
    "y = df.polarity\n",
    "\n",
    "# Train a LinearSVC classifier\n",
    "svc = LinearSVC()\n",
    "svc.fit(X, y)\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the words in the sentences from before\n",
    "vectors = vectorizer.transform(sentences.content)\n",
    "\n",
    "new_scores = sentences.copy()\n",
    "\n",
    "# SVC predictions\n",
    "new_scores['pred_svc'] = svc.predict(vectors)\n",
    "new_scores['svc_score'] = svc.decision_function(vectors)\n",
    "\n",
    "# Bayes predictions + probabilities\n",
    "new_scores['pred_bayes'] = bayes.predict(vectors)\n",
    "# Proability that it's positive\n",
    "new_scores['bayes_positive_prob'] = bayes.predict_proba(vectors)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out our results\n",
    "\n",
    "Beware that the scoring here isn't the same as up above! That's why we're skipping out on the coloring this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(svc, vec=vectorizer, top=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying with the Washington Post\n",
    "\n",
    "We'll be reproducing part of [Apple says its App Store is â€˜a safe and trusted place.â€™ We found 1,500 reports of unwanted sexual behavior on six apps, some targeting minors](https://www.washingtonpost.com/technology/2019/11/22/apple-says-its-app-store-is-safe-trusted-place-we-found-reports-unwanted-sexual-behavior-six-apps-some-targeting-minors/?arc404=true), from the Washington Post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 300)\n",
    "\n",
    "# Read in our data, then drop ones without a text\n",
    "# review and get rid of a few unwannted columns\n",
    "df = pd.read_csv(\"reviews-marked.csv\")\n",
    "df = df.dropna(subset=['Review'])\n",
    "df = df.drop(columns=['Country', 'Date', 'Version'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our dataset into ones we've labeled and ones that don't have labels yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known = df[df.sexual.notna()].copy()\n",
    "unknown = df[df.sexual.isna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the words inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(known.Review)\n",
    "\n",
    "# Build a dataframe of words, purely out of curiosity\n",
    "words_df = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier to understand the difference between the two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500, max_df=0.30)\n",
    "matrix = vectorizer.fit_transform(known.Review)\n",
    "\n",
    "X = matrix\n",
    "y = known.sexual\n",
    "\n",
    "clf = LinearSVC(class_weight='balanced')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(unknown.Review)\n",
    "\n",
    "unknown['predicted'] = clf.predict(X)\n",
    "unknown['predicted_proba'] = clf.decision_function(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many are in each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown.predicted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which ones might we be interested in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown.sort_values(by='predicted_proba', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it make those decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.explain_weights(clf, vec=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
